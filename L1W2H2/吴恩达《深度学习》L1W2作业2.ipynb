{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "44C8026B2A3D4F7EAF5F8F13FA1C9228",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "# 用神经网络思想实现Logistic回归\n",
    "\n",
    "欢迎来到你的第一个编程作业！ 你将学习如何建立逻辑回归分类器用来识别猫。 这项作业将引导你逐步了解神经网络的思维方式，同时磨练你对深度学习的直觉。\n",
    "\n",
    "\n",
    "**说明：**\n",
    "除非指令中明确要求使用，否则请勿在代码中使用循环（for / while）。\n",
    "\n",
    "**你将学习以下内容：**\n",
    "* 建立学习算法的一般架构，包括：\n",
    "\t* \t初始化参数\n",
    "\t* \t计算损失函数及其梯度\n",
    "\t* \t使用优化算法（梯度下降）\n",
    "* 按正确的顺序将以上所有三个功能集成到一个主模型上。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "DF7CD12B09824F908222DD939CE5B7DB",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "## 1- 安装包##\n",
    "\n",
    "首先，让我们运行下面的单元格，以导入作业中所需的包。\n",
    "* [numpy](www.numpy.org) 是Python科学计算的基本包。\n",
    "* [h5py](http://www.h5py.org)是一个常用的包，可以处理存储为H5文件格式的数据集。\n",
    "* [matplotlib](http://matplotlib.org)是一个著名的Python图形库。\n",
    "* 这里最后通过[PIL]（http://www.pythonware.com/products/pil/）和[scipy](https://www.scipy.org/) 使用你自己的图片去测试模型效果。"
   ]
  },
  {
   "metadata": {
    "id": "11378DD8FA5648998394E0A00228381D",
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "text": "/home/kesci/input/deeplearningai17761\n",
     "name": "stdout"
    }
   ],
   "source": [
    "cd ../input/deeplearningai17761"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "AE41E025E50B45B295BB4C814339A154",
    "scrolled": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-14T08:03:39.106644Z",
     "start_time": "2024-03-14T08:03:37.638612Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from datasets.lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "C903C89DCA2B482BB715EA420B783EEA",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "## 2- 问题概述##\n",
    "\n",
    "**问题说明**：你将获得一个包含以下内容的数据集（\"data.h5\"）：\n",
    "*      标记为cat（y = 1）或非cat（y = 0）的**m_train**训练图像集\n",
    "*      标记为cat或non-cat的**m_test**测试图像集\n",
    "*      图像维度为（num_px，num_px，3），其中3表示3个通道（RGB）。 因此，每个图像都是正方形（高度= num_px）和（宽度= num_px）。\n",
    "\n",
    "你将构建一个简单的图像识别算法，该算法可以将图片正确分类为猫和非猫。\n",
    "让我们熟悉一下数据集吧， 首先通过运行以下代码来加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "172CE9E4A8214F82B0392A74773C8F62",
    "scrolled": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-14T08:03:45.766471Z",
     "start_time": "2024-03-14T08:03:45.752525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "3065A29BDD2F412B92534BC95F9A48F2",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "我们在图像数据集（训练和测试）的末尾添加了\"_orig\"，以便对其进行预处理。 预处理后，我们将得到train_set_x和test_set_x（标签train_set_y和test_set_y不需要任何预处理）。\n",
    "\n",
    "train_set_x_orig和test_set_x_orig的每一行都是代表图像的数组。 你可以通过运行以下代码来可视化示例。 还可以随意更改`index`值并重新运行以查看其他图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "AD52F14FA9B642B989AFDA66C319B43A",
    "collapsed": false,
    "scrolled": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-14T08:03:48.963641Z",
     "start_time": "2024-03-14T08:03:48.846846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [0], it's a 'non-cat' picture.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 10\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "1AAA47CDF0944B31AE91376B1E774A65",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "深度学习中的许多报错都来自于矩阵/向量尺寸不匹配。 如果你可以保持矩阵/向量的尺寸不变，那么将消除大多错误。\n",
    "\n",
    "**练习：** 查找以下各项的值：\n",
    "*      m_train（训练集示例数量）\n",
    "*      m_test（测试集示例数量）\n",
    "*      num_px（=训练图像的高度=训练图像的宽度）\n",
    "\n",
    "请记住，“ train_set_x_orig”是一个维度为（m_train，num_px，num_px，3）的numpy数组。 例如，你可以通过编写“ train_set_x_orig.shape [0]”来访问“ m_train”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "A76A8CF63B524EDB8864C8B997F2217E",
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "Number of training examples: m_train = 209\nNumber of testing examples: m_test = 50\nHeight/Width of each image: num_px = 64\nEach image is of size: (64, 64, 3)\ntrain_set_x shape: (209, 64, 64, 3)\ntrain_set_y shape: (1, 209)\ntest_set_x shape: (50, 64, 64, 3)\ntest_set_y shape: (1, 50)\n",
     "name": "stdout"
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "C3E15E52444047F281369E10ADE371DB",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**：\n",
    "训练集数量：m_train = 209\n",
    "测试集数量：m_test = 50\n",
    "每个图像的高度/宽度：num_px = 64\n",
    "每个图像的大小：（64，64，3）\n",
    "train_set_x维度：（209、64、64、3）\n",
    "trainsety维度：（1，209）\n",
    "test_set_x维度：（50、64、64、3）\n",
    "test_set_y维度：（1，50）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "76DD435D2EDE4BDC8F332C9C2E67F67D",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "为了方便起见，你现在应该以维度(num_px $*$ num_px $*$ 3, 1)的numpy数组重塑维度（num_px，num_px，3）的图像。 此后，我们的训练（和测试）数据集是一个numpy数组，其中每列代表一个展平的图像。 应该有m_train（和m_test）列。\n",
    "\n",
    "**练习：** 重塑训练和测试数据集，以便将大小（num_px，num_px，3）的图像展平为单个形状的向量(num\\_px $*$ num\\_px $*$ 3, 1)。\n",
    "\n",
    "当你想将维度为（a，b，c，d）的矩阵X展平为形状为(b$*$c$*$d, a)的矩阵X_flatten时的一个技巧是：\n",
    "```python\n",
    "X_flatten = X.reshape（X.shape [0]，-1）.T     ＃ 其中X.T是X的转置矩阵\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "99FE56CF4FE142B98DD32763A7AFE3AE",
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "train_set_x_flatten shape: (12288, 209)\ntrain_set_y shape: (1, 209)\ntest_set_x_flatten shape: (12288, 50)\ntest_set_y shape: (1, 50)\nsanity check after reshaping: [17 31 56 22 33]\n",
     "name": "stdout"
    }
   ],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "566C3435990A41928684827E578BA1EB",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**：\n",
    "train_set_x_flatten维度：（12288，209）\n",
    "trainsety维度：（1，209）\n",
    "test_set_x_flatten维度：（12288，50）\n",
    "test_set_y维度：（1，50）\n",
    "重塑后的检查维度：[17 31 56 22 33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "161C9D76A24A49028389C881855DBFEA",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "为了表示彩色图像，必须为每个像素指定红、绿、蓝色通道（RGB），因此像素值实际上是一个从0到255的三个数字的向量。\n",
    "\n",
    "机器学习中一个常见的预处理步骤是对数据集进行居中和标准化，这意味着你要从每个示例中减去整个numpy数组的均值，然后除以整个numpy数组的标准差。但是图片数据集则更为简单方便，并且只要将数据集的每一行除以255（像素通道的最大值），效果也差不多。\n",
    "\n",
    "在训练模型期间，你将要乘以权重并向一些初始输入添加偏差以观察神经元的激活。然后，使用反向梯度传播以训练模型。但是，让特征具有相似的范围以至渐变不会爆炸是非常重要的。具体内容我们将在后面的教程中详细学习！\n",
    "\n",
    "开始标准化我们的数据集吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "909CA96ACD524D148A8FE51D78B7677A",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "BA9892621923421A9CBF415F07BE4AB6",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**你需要记住的内容：**\n",
    "\n",
    "预处理数据集的常见步骤是：\n",
    "* 找出数据的尺寸和维度（m_train，m_test，num_px等）\n",
    "* 重塑数据集，以使每个示例都是大小为（num_px \\ * num_px \\ * 3，1）的向量\n",
    "* “标准化”数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "9FB29993EBAA4992B975D45824C03D7E",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "## 3- 学习算法的一般架构##\n",
    "\n",
    "现在是时候设计一种简单的算法来区分猫图像和非猫图像了。\n",
    "\n",
    "你将使用神经网络思维方式建立Logistic回归。 下图说明了为什么“逻辑回归实际上是一个非常简单的神经网络！”\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q15kx21spv.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "**算法的数学表达式**：\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$z^{(i)} = w^T x^{(i)} + b \\tag{1}$\n",
    "$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$ \n",
    "$$\n",
    "\\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}\n",
    "$$\n",
    "\n",
    "The cost is then computed by summing over all training examples:\n",
    "$$\n",
    "J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}\n",
    "$$\n",
    "\t\t\n",
    "**关键步骤**：\n",
    "在本练习中，你将执行以下步骤：\n",
    "*      初始化模型参数\n",
    "*      通过最小化损失来学习模型的参数\n",
    "*      使用学习到的参数进行预测（在测试集上）\n",
    "*      分析结果并得出结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "0EAC454E062C4D52A9118A7AAAAB0D67",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "## 4- 构建算法的各个部分##\n",
    "\n",
    "建立神经网络的主要步骤是：\n",
    "1.定义模型结构（例如输入特征的数量）\n",
    "2.初始化模型的参数\n",
    "3.循环：\n",
    "*      计算当前损失（正向传播）\n",
    "*      计算当前梯度（向后传播）\n",
    "*      更新参数（梯度下降）\n",
    "\n",
    "你通常会分别构建1-3，然后将它们集成到一个称为“ model（）”的函数中。\n",
    "\n",
    "### 4.1- 辅助函数\n",
    "\n",
    "**练习**：使用“Python基础”中的代码，实现`sigmoid（）`。 如上图所示，你需要计算$sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ 去预测。 使用np.exp（）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "81F71A54ADCE45CDA2BDB4E996D7C673",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "CCFAA44915914F1E94DF5807B4D1E423",
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "sigmoid([0, 2]) = [0.5        0.88079708]\n",
     "name": "stdout"
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "D007BFFA95D648199A2D3B57682D9482",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**: \n",
    "sigmoid([0, 2]) = [0.5        0.88079708]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "36B63B1202A549F18C69D64841DDC6C8",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "### 4.2- 初始化参数\n",
    "\n",
    "**练习：** 在下面的单元格中实现参数初始化。 你必须将w初始化为零的向量。 如果你不知道要使用什么numpy函数，请在Numpy库的文档中查找np.zeros（）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "8ABE2060998C43AC99916E833B6A64C6",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "0CD547641AA44FD08D9AC53052002F7B",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "w = [[0.]\n [0.]]\nb = 0\n",
     "name": "stdout"
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "C232F03FA0F74D739A014839C217AE65",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**: \n",
    "w = [[0.]\n",
    "[0.]]\n",
    "b = 0\n",
    "\n",
    "\n",
    "对于图像输入，w的维度为(num_px $\\times$ num_px $\\times$ 3, 1)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "D7A2929C11B349718327F1DB79F0B585",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "### 4.3- 前向和后向传播\n",
    "\n",
    "现在，你的参数已初始化，你可以执行“向前”和“向后”传播步骤来学习参数。\n",
    "\n",
    "**练习：** 实现函数propagate（）来计算损失函数及其梯度。\n",
    "\n",
    "**提示**：\n",
    "\n",
    "正向传播：\n",
    "* 得到X\n",
    "* 计算$A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "* 计算损失函数：$J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "你将要使用到以下两个公式：\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "8DB1AFC11EC64A9080D263AB25DC88B9",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)            # compute activation\n",
    "    cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))         # compute cost\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    dw = 1 / m * np.dot(X, (A - Y).T)\n",
    "    db = 1 / m * np.sum(A - Y)\n",
    "    ### END CODE HERE ###\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "77781A6736AA4E808AD78A68A66813CA",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "dw = [[0.99993216]\n [1.99980262]]\ndb = 0.49993523062470574\ncost = 6.000064773192205\n",
     "name": "stdout"
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "6E4A28DA2046408BBD18DE3D0FE8FA8D",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**:\n",
    "dw = [[0.99993216]\n",
    " [1.99980262]]\n",
    "db = 0.49993523062470574\n",
    "cost = 6.000064773192205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "8241762441A44A16A761EE664900765B",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "### d）优化函数\n",
    "* 初始化参数。\n",
    "* 计算损失函数及其梯度。\n",
    "* 使用梯度下降来更新参数。\n",
    "\n",
    "**练习：** 写下优化函数。 目标是通过最小化损失函数 $J$ 来学习 $w$ 和 $b$。 对于参数$\\theta$，更新规则为$\\theta = \\theta - \\alpha \\text{ }  d\\theta$，其中$\\alpha$是学习率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "113344FF60D4474BBCF6E2711FD08CD7",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        ### START CODE HERE ### \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        ### START CODE HERE ###\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "E74C2694CE6949F79921B49D1C1FD2B1",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "w = [[0.1124579 ]\n [0.23106775]]\nb = 1.5593049248448891\ndw = [[0.90158428]\n [1.76250842]]\ndb = 0.4304620716786828\n[6.000064773192205]\n",
     "name": "stdout"
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "C27D7E49616F43BF80D68986171C5217",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**: \n",
    "w = [[0.1124579 ]\n",
    " [0.23106775]]\n",
    "b = 1.5593049248448891\n",
    "dw = [[0.90158428]\n",
    " [1.76250842]]\n",
    "db = 0.4304620716786828\n",
    "[6.000064773192205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "7BD13AF784F34A8B9463ED3784FFA873",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**练习：** 上一个函数将输出学习到的w和b。 我们能够使用w和b来预测数据集X的标签。实现`predict（）`函数。 预测分类有两个步骤：\n",
    "1.计算$\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "2.将a的项转换为0（如果激活<= 0.5）或1（如果激活> 0.5），并将预测结果存储在向量“ Y_prediction”中。 如果愿意，可以在for循环中使用if / else语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "D2036B868BF14D4D85D270A7B1B9DE20",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        if A[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "1EFA81E9460C4CC8940C5699BB12CF30",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "predictions = [[1. 1.]]\n",
     "name": "stdout"
    }
   ],
   "source": [
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "5F14960D06404F65B3E483CC4197FF46",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**: \n",
    "predictions = [[1. 1.]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "7433AC4720244B078F79F6D2B7B155AD",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**你需要记住以下几点：**\n",
    "你已经实现了以下几个函数：\n",
    "* 初始化（w，b）\n",
    "* 迭代优化损失以学习参数（w，b）：\n",
    "\t*     计算损失及其梯度\n",
    "\t*     使用梯度下降更新参数\n",
    "* 使用学到的（w，b）来预测给定示例集的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "B1310A7D971047C1827D6550A5C0C5E4",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "## 5- 将所有功能合并到模型中##\n",
    "\n",
    "现在，将所有构件（在上一部分中实现的功能）以正确的顺序放在一起，从而得到整体的模型结构。\n",
    "\n",
    "**练习：** 实现模型功能，使用以下符号：\n",
    "*      Y_prediction对测试集的预测\n",
    "*      Y_prediction_train对训练集的预测\n",
    "*      w，损失，optimize（）输出的梯度\n",
    "\t\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "38BDB18490F544F1ABE51A02D60B42DE",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros (≈ 1 line of code)\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "3466DB83E61D493C8A8E3F8C84F77283",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "运行以下单元格训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "362C4259BD8F44EA8D0E2513C387ADBF",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "Cost after iteration 0: 0.693147\nCost after iteration 100: 0.584508\nCost after iteration 200: 0.466949\nCost after iteration 300: 0.376007\nCost after iteration 400: 0.331463\nCost after iteration 500: 0.303273\nCost after iteration 600: 0.279880\nCost after iteration 700: 0.260042\nCost after iteration 800: 0.242941\nCost after iteration 900: 0.228004\nCost after iteration 1000: 0.214820\nCost after iteration 1100: 0.203078\nCost after iteration 1200: 0.192544\nCost after iteration 1300: 0.183033\nCost after iteration 1400: 0.174399\nCost after iteration 1500: 0.166521\nCost after iteration 1600: 0.159305\nCost after iteration 1700: 0.152667\nCost after iteration 1800: 0.146542\nCost after iteration 1900: 0.140872\ntrain accuracy: 99.04306220095694 %\ntest accuracy: 70.0 %\n",
     "name": "stdout"
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "40B908265E7A4C90B4343C4E631A3288",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**预期输出**: \n",
    "train accuracy: 99.04306220095694 %\n",
    "test accuracy: 70.0 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "E791DEB85B214A12A0A506E43B9CF4B4",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**评价**：训练准确性接近100％。 这是一个很好的情况：你的模型正在运行，并且具有足够的容量来适合训练数据。 测试误差为68％。 考虑到我们使用的数据集很小，并且逻辑回归是线性分类器，对于这个简单的模型来说，这实际上还不错。 但请放心，下周你将建立一个更好的分类器！\n",
    "\n",
    "此外，你会看到该模型明显适合训练数据。 在本专业的稍后部分，你将学习如何减少过度拟合，例如通过使用正则化。 使用下面的代码（并更改`index`变量），你可以查看测试集图片上的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "ED09E8724F694DBFAC6E963D8FD68D6F",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "y = 1, you predicted that it is a \"cat\" picture.\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/ED09E8724F694DBFAC6E963D8FD68D6F/q15mtru0dr.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 1\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "061B89DE7D6A474483AE16B1C8168252",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "让我们绘制损失函数和梯度吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "6BE9377DED634AB690C30677A1C2E2B3",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/6BE9377DED634AB690C30677A1C2E2B3/q15mtsthx1.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "24E878284D6C49A58600AFF680DAF014",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**解释**：\n",
    "损失下降表明正在学习参数。 但是，你看到可以在训练集上训练更多模型。 尝试增加上面单元格中的迭代次数，然后重新运行这些单元格。 你可能会看到训练集准确性提高了，但是测试集准确性却降低了。 这称为过度拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "B656750B8A294A31827503E052A9205E",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "\n",
    "## 6- 进一步分析（可选练习）##\n",
    "\n",
    "祝贺你建立了第一个图像分类模型。 让我们对其进行进一步分析，并研究如何选择学习率$\\alpha$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "A81C3149213B4D7E880FEDBB66C7D637",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "#### 学习率的选择 ####\n",
    "\n",
    "**提醒**：\n",
    "为了使梯度下降起作用，你必须明智地选择学习率。 学习率$\\alpha$决定我们更新参数的速度。 如果学习率太大，我们可能会“超出”最佳值。 同样，如果太小，将需要更多的迭代才能收敛到最佳值。 这也是为什么调整好学习率至关重要。\n",
    "\n",
    "让我们将模型的学习曲线与选择的几种学习率进行比较。 运行下面的单元格。 这大约需要1分钟。 还可以尝试与我们初始化要包含的“ learning_rates”变量的三个值不同的值，然后看看会发生什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "E351227574C845758992A95BE3F10621",
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "learning rate is: 0.01\ntrain accuracy: 99.52153110047847 %\ntest accuracy: 68.0 %\n\n-------------------------------------------------------\n\nlearning rate is: 0.001\ntrain accuracy: 88.99521531100478 %\ntest accuracy: 64.0 %\n\n-------------------------------------------------------\n\nlearning rate is: 0.0001\ntrain accuracy: 68.42105263157895 %\ntest accuracy: 36.0 %\n\n-------------------------------------------------------\n\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/E351227574C845758992A95BE3F10621/q15mtyn7i3.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "2F6435CF24AB41BD80C89981EB66D916",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "\t\t\n",
    "**解释**：\n",
    "* 不同的学习率会带来不同的损失，因此会有不同的预测结果。\n",
    "* 如果学习率太大（0.01），则成本可能会上下波动。 它甚至可能会发散（尽管在此示例中，使用0.01最终仍会以较高的损失值获得收益）。\n",
    "* 较低的损失并不意味着模型效果很好。当训练精度比测试精度高很多时，就会发生过拟合情况。\n",
    "* 在深度学习中，我们通常建议你：\n",
    "\t*      选择好能最小化损失函数的学习率。\n",
    "\t*      如果模型过度拟合，请使用其他方法来减少过度拟合。 （我们将在后面的教程中讨论。）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "34CE567D3E0246DE8F324164A0AFF6BE",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "\n",
    "## 7-使用自己的图像进行测试（可选练习）##\n",
    "\n",
    "祝贺你完成此作业。 你可以使用自己的图像并查看模型的预测输出。 要做到这一点：\n",
    "     1.单击此笔记本上部栏中的 \"File\"，然后单击\"Open\" 以在Coursera Hub上运行。\n",
    "     2.将图像添加到Jupyter Notebook的目录中，在\"images\"文件夹中\n",
    "     3.在以下代码中更改图像的名称\n",
    "     4.运行代码，检查算法是否正确（1 = cat，0 = non-cat）！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "5A8BBAE5BFD2497E8D5A1D2EA24DDE74",
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imresize` is deprecated!\n`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\nUse Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n  \n",
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": "y = 1.0, your algorithm predicts a \"cat\" picture.\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "metadata": {
      "needs_background": "light"
     },
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "text/html": "<img src=\"https://cdn.kesci.com/rt_upload/5A8BBAE5BFD2497E8D5A1D2EA24DDE74/q15mtz9svb.png\">"
     },
     "transient": {}
    }
   ],
   "source": [
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "#my_image = \"cat_in_iran.jpg\"   # change this to the name of your image file \n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = '/home/kesci/input/deeplearningai17761/cat_in_iran.jpg'\n",
    "image = np.array(plt.imread(fname))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "A8AF7111C6794A15881AD6479D141F03",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "**此作业要记住的内容：**\n",
    "\n",
    "1. 预处理数据集很重要。\n",
    "1. 如何实现每个函数：initialize（），propagation（），optimize（），并用此构建一个model（）。\n",
    "1. 调整学习速率（这是“超参数”的一个示例）可以对算法产生很大的影响。 你将在本课程的稍后部分看到更多示例！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "6B3611425A824BF4AB72C67072D1D674",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "最后，如果你愿意，我们邀请你在此笔记本上尝试其他操作。 在尝试任何操作之前，请确保你正确提交。 提交后，你可以学习了解的包括：\n",
    "*      发挥学习率和迭代次数\n",
    "*      尝试不同的初始化方法并比较结果\n",
    "*      测试其他预处理（将数据居中，或将每行除以其标准偏差）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "id": "A674A5B3D48E4F9C85B0869052F66100",
    "mdEditEnable": false,
    "tags": []
   },
   "source": [
    "参考书目：\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  },
  {
   "metadata": {
    "id": "09DA48672F2745678D6B067C6EE0799B",
    "slideshow": {
     "slide_type": "slide"
    },
    "collapsed": false,
    "scrolled": false,
    "tags": []
   },
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
